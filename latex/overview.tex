\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}

\title{Positivity-preserving adaptive Runge-Kutta methods: results}
\author{Stephan Nuesslein}

\begin{document}

\maketitle

With increasing complexity of the right hand side a step requect has a high cost. 
The goal of the project is to develop a positivity preserving method that uses adaptive b-Coefficients for every step.  This means that the computed stage values can be used and don't have to be recomputed. 
The resulting b should comply with the order conditions as far as possible.

Important things to point out:
Approach preserves linear invariants
Not cost anything if there are no negative components (exept for the test)

(Note: The problem is connected to the theory about embedded methods, in the sense that one have different RKM with the same set of stage values. It may be interesting to have some literature regarding this)

\section{Main Idea}

When computing the solution of an ODE $u ' = f(t,u) $ using a RK Method with $s$ Stages we first compute the stage values 

\begin{equation}
k^{(j)} =  f(t^n + \Delta t c_j, u^n + \Delta t \sum_{l = 1}^{s} a_{jl} k^{(l)}  \quad j = 1,\cdots,s)
\end{equation}

Afterwards we calculate the solution 

\begin{equation}
u^{n+1} = u^n + \Delta t \sum_{j  = 1}^s k^{(j)} b_j .
\end{equation}

This equation can be formulated to

\begin{equation}\label{eq:Combination}
u^{n+1} = u^n + \Delta t K b
\end{equation}

where $K$ is a matrix containing the stage values $k_1,\cdots,k_s$.

One reason why steps are requected is that the new solution does not comply with positifity. 
So it may be adventagious to adapt Equation\,\ref{eq:Combination} in such a way that $u^{n+1}$ is positive. This is done by adapting the weights $b$.
As we can see in Equation\,\ref{eq:Combination} $u^{n+1}$ depends linearly on the stage values.
When altering the weights the Order Conditions should be still meet. 
Because $A$ is already fixed the Order Conditions reduce to linear equations.
This means that finding the $b$ can be done by solving a linear Programming problem.
 



Flowchart to evaluate a step:

\begin{itemize}
\item Calculate the stage values $k_1,\cdots,k_s$
\item Calculate the $u_{n+1} = u_n + \Delta t K b_{d}$ with a default b
\item Test $u_{n+1} \geq 0$, if not:
\item find a new b with $u_n + \Delta t K b \geq 0$
\item Calculate the $u_{n+1} = u_n + \Delta t K b$ with the new b
\end{itemize}


\section{Applicable Problems}
The approach can be used with ODE systems $u' = f(t,u)$ that ensure  $u(t) \geq 0 \forall_t \forall_{  u_0 \geq 0}$ 

This can be tested with the property 
\begin{equation}
u_i=0 \Rightarrow f_i(t,u_1,\cdots,u_i,\cdots,u_n) \geq 0  \forall_{u_c \geq 0} \forall_{t}
\end{equation}

For problems where only the combination of $f(t,u)$ and $u_0$ leads to positifity tests did not show promising results, additional it is not sure if the computed solution is reasonable.

\section{Details}

\subsection{Positifity}
For solving an PDE with the method of lines an spartial grid  with $m$ points is introduced. 
From this we get an ODE with an $u \in R^m$.

To enshure that the solution is positive 

\begin{align}
 u_i^{n+1} &\geq 0   \;   \forall_{i \in \{1, \cdots,m \}}  \\
 u_i^n + h \sum_{j=0}^{s-1} b_j h_i^j  &\geq 0   \;   \forall_{i \in \{1,\cdots,m \}}  
\end{align}

has to be fulfilled.
This infers $p$ positivity constraints to the optimisation problem. These can be written as

\begin{equation}
u_i + \Delta t K  b \geq 0     
\end{equation}

where $K = \big[k^1 , \cdots k^{s-1}\big]$.


This causes unnecessary many inequality constraints on the LP-Problem. To simplify the problem we want to reduce the positifity constraints at places where there is no issue with positifity.

For this we write
\begin{equation}
u_i^n + \Delta b \sum_{j=0}^{s-1} b_j h_i^j  \geq 0   \;   \forall_{i \in h \subseteq \{1,\cdot,m \}} 
\end{equation}

Now we have to choose a $h \subseteq \{1,\cdots,m \}$ that include all indecies that are needed for determining the $b$.

A reasonable approach is to set $h_0 = \{ i \in \{1,\cdots,m \} |  u_i^{n+1}  < 0 \}$. 
After the solution with the reduced set is computed, the algorithm has to check if the positifity of the other values $i \notin h \subseteq \{1,\cdot,m \}$ is still meet. 
If the conditions is not meet a new set $h_{a+1} = \{ i \in \{1,\cdots,m \}|  u_i^{n+1}  < 0 \} \cup h_{a}$ using the new $u_i^{n+1}$ is generated and the LP-Problem is solved again. This process id repeated until a solution is found that leads to a $u_{n+1} \geq 0$. The choice of $h_{a+1}$ based on the $h_{a}$ ensures that the algorithm cannot get stuck in a loop. In the worst case $h_a$ is growing very slowly until $h_a = \{1,\cdots,m \}$. 

This effect did not occur so far. A approach on this would be to make a educated guess which indecies could get a problem with positifity. A possible estimate would be $\frac{u_i^{n+1}}{max(K_{(i,0)}, \cdots ,K_{(i,0)})} $ 

When enforcing a maximum value we can do the same. When both enforcing maximum and minimum values we have two separate sets of active constraints $k_{min}$ and $k_{max}$ where $k_{max}$ denotes the set of active maximum constraints and $k_{min}$ denotes the set of active minimum constraints. 
Here it is important to update these sets simultaneously.  


\subsection{Order Conditions}

The Order Conditions are an linear equations system and can be written as $Q b = r$. 

The vector $b \in R^s$ contains the b coefficients. $s$ is the number of stages. $Q$ is an $n \times s$ matrix, where $g$ is the number of Order Conditions. $r$ is an vector containing the right hand side of the Order Conditions

If the $A$ of a  preexisting RK-method is used, there is at least one solution for the linear equation system.
In order to get an optimization problem the equation system has to be underdetermined.
This implies that $rank{Q} < s$. 
Because the Quadrature Conditions are linear independent, there are at least $q$ independent vectors in $Q$. This leads to the $p < s$.
This implies that the number of stages has to be higher as the wanted required order.


\subsection{Ways to formulate the Optimization Problem}

There are two possible ways to write down the adaptation of the $b$. The first way is to directly adapt the $b$ by adding a correction  $\Delta b$ that ensures positivity. 
This is the easiest way to adapt the $b$. An advantageous property is that the step size can be reduced after calculation the stage values by using the dense output order conditions.  
(Note: Recommendation for explicit methods)

The second approach is to choose $b$ as a convex combination of a set of $b$s. This approach is more useful if some embedded methods with certain properties are know. 
This approach is also shows more  predictable behavior because the resulting $u^{n+1}_b$ is also a convex combination of the solutions $u^{n+1}_{b_1},u^{n+1}_{b_2},\cdots$ 
(Note: Recommendation for implicit methods)


Both approaches are explained in more detail in the following sections.


\subsection{Direct Adaptation}

The Direct Adaptation approach leads to two set of constraints on the $b$.

The first set of constraints is the positifity and can be written as 
$$u_{n+1}=u_n+\Delta K \vec{b} \geq 0$$

The second set of constraints are the Order Conditions
$$Qb=r$$

The weights $b = b_{orig} + \Delta b$ consist of the weights $b_{orig}$ of the original method and an adaption $\Delta b$. This $\Delta b \in ker \{ Q \}$. 

To determine the optimal $b$ a objective function is needed.
Different types of objective functions have been tried. (Notebook: objectives.ipynb)

\begin{description}

\item[L1 norm] The optimisation Problem opimises for $min(|b-rkm.b|_1)$
            
\item[Quadrature]   The optimisation Problem opimises for $min(|bTq-r|)$
                            where q is the quadrature condition of the next higher order 
                            and r is the expected right hand side
            
\item[Hom. Order]    The optimisation Problem opimises for $min(|bTO|)$ where O are the homogenus Order Conditions of the next higher orders
                            
 
\end{description}

A reasonable property of the objective function would be that for a set of $b$ only constrained by the order condition the LP-Problem gives $b = b_{orig}$ as optimal solution.  $argmin(f_{optim}(b)) = b_{orig}$. In practice this also means that there is no need to solve solve the optimization Problem if no constraints are violated because the solution of this problem is already known. This is adventagious for performance reasons.
The different approaches have been tested for a test problem from Kopecz and Meister 2018 (Two substances reacting). The optimization problem was used at every step.
The magnitude of $b$ can get large if the Order Conditions are used as objective function.
By changing the $b$ the stability function is altered. This can lead to oscillations if the poles of the rhs are no longer in the stability region of the resulting method.
For this reason $||b-b_{orig}||$ seems like a good choice. The Norm $||x||_1$ can be implement the with Linear Programming using slack variables. We choose $||b_{optim}-b_{orig}||_1$ as objective function.

Large values of b can lead to numerical instability. Because $\sum_{i  = 1}^s b_i = 1$, a increase of $|b|$ leads to a combination of negative and positive values. Because the computation only is done with a finite precision (and usually in floating point) large $||b||$ can lead to absorption effects.    


\subsubsection{Adaption of Timestep using the dense output formual}

If the original step $\Delta t$ was to large and there is no suitable $b$, we would like to calculate a $u^(n+1)$ using the stage values instead of rejecting the step. For this the time step is reduced after calculation the stage values. This can be done using the Order Conditions for dense Output (todo: Source for this).
We introduce $\theta \in [0,1]$. The new step taken has the length $\theta \Delta t$ whereas $\Delta t$ is the time step used when calculating the Stagevalues.
To calculate a reduced step the Order Conditions have to be adapted and a new $b_{orig}$ for the objective function (and more important the Error detection afterwards) has to be generated. 
(TODO: the $b_{orig}$ is still a open question)

When adapting the Order Condition to a new $\theta$ the Order Condition Matrix $Q$ stays unchanged whereas the right hand side depends on $\theta$.

The dependency of $r(\theta)$ is nonlinear. This means that the maximum $\theta$ with a suitable $b$ can not be calculated by using a LP-Problem. This means that different $\theta$ have to be tested independently. 
(Note: we could include some algorithm to search for it)


\subsection{Convex combination of existing methods}
For some test problems (e.g. the Heat Equation solved with an implicit method), large distortions occur, even though a norm of the distortion of the b is used as a objective function. 
For implicit methods it is known that implicit euler steps lead to a positive solution for any $\Delta t$. The backward Euler is still only first Order but shows more exact results in certain cases than a method of higher Order that shows distortions of the solution caused by the larger error coefficients ($\Delta t \gg 0$, so they do not disappear because of the nature of the polynomial).
A possible method to fix this is to generate the new b based on a convex combination of embedded methods of RKM. 

todo: write this down in more detail with proofs
$b$ is in a convex hull of al b
If all the used b complie with an order conditions the new method also has this order

$$ q^T b = q^T (\chi b_{\alpha} + (1-\chi) b_{\beta}) = \chi q^T  b_{\alpha} + (1-\chi) q^T  b_{\beta}) = \chi rhs + (1-\chi) rhs = rhs$$


The optimisation problem is changed to:

$$u_{n+1}=u_n+\Delta K \vec{b} \geq 0$$

with

$$ \vec{b} = \sum_i^d a_i \vec{b_i}$$

$$ \forall_{i \in \{1, \cdots d \}} 0 \leq a_1 \leq 1$$

and the objective

$$ min \left(\sum_i^d w_i a_i \right) $$

with some weighting factors $w_1,\cdots,w_d$. The weighting factors determine which is the preferred b to use.

Because the optimal solution of the unconstrained problem has to be the original $b$ the weight $w_0$ corresponding to $b_{orig}$ should be the smallest $w$. This weight is simply set to $w_{b_{orig}} = 0$. For the other weights $w_i = \frac{1}{Order\{b_i\}}$ is used.

For methods with $s \geq p$ we would still like to have some degrees of freedom for the highest order. For this we have to introduce at least one $b$ that complies with the order Condition of the highest order and $b \neq b_{orig}$.
These additional $b$ can be constructed by calculating a Span $S$ of the Kernel $ker Q$ of the Order Condition Matrix $Q$. For every vector $s \in S$ one set of weights with $b = b_{orig} + a s$ and one with $b = b_{orig} - a s$ is added. The $a$ is a parameter that determines how big a change is allowed. 

As a first order method a $b$ is added that corresponds to a series of backward euler steps. These are know to be yield to a positive result (Todo: source).

An important property of the embedded methods is that they should show the desired stability characteristics.

A Reduction of the step size suing the order Conditions for dense output would also be possible. For this 
Doing dense Output here is a bit complicated, but it would not help ensure positifity only (maybe) increase exactness. (Note: is it worth exploring this or is it better to just leave this open for further research it may be also interesting regardless the study of positifity)
Everything has downsides...
 


\subsection{Choice of Baseline method}

Existence of embedded methods and corresponding degrees of freedom for the b

\# TODO We could introduce some table here with the dimensions of the embedded methods for different methods and orders.

Stability region in comparison with the maximum timestep that ensures positifity. 

Existence of a positive solution. This boils down to the question if there is a embedded first order method that ensures positivity. This is particularly interesting for Implicit methods, because the $\Delta t$ is not limited by the stability. 
If we have a embedded first Order Method we can ensure that there is always a positive solution, which might be of first Order. 

\subsection{Error detection/Approximation}
The main question is: We see that for certain $b$ that comply with the Order Conditions we get results that do not resemble the solution. (some type of glitches, artefacts)

Note: in general it is difficult to give some mathematically rigorous statement for this statement because -by definition- it only applies for $\delta t \gg 0$ where the proofs using the Taylor Series do not give valid results any more. We could say that the main idea of the adaption of $b$ is to alter the error in a certain way that we know that the numerical solution gets 'better' in the sense that it only leads to positive solutions. 
When taking the Taylor Series of the numeric solution the coefficients up to the Order of the method are fixed by the Order Conditions. The only degrees of freedom are the coefficents above the Order Conditions. This requires that $\Delta t > 0$. (More like $\Delta t^n \approx \Delta t^(n+1) $)
The main way is to ensure that for $\Delta t \to 0$ : $b \to b_{orig}$. For this case we already know that the numeric solution converges to the exact solution.  
This is made sure by property of the Objective function that $argmin(f_{optim}(b)) = b_{orig}$. 

To make sure that the new adapted solution is still reasonable we measure the deviation form the Original method. In the worst case the errors add up. (todo: here some math formula... (We know that can not be the case because we already know that we will reduce the error for the quantity we will make positive, still we can use it as a upper bound.))


\subsection{Stability region}

By adapting the $b$ we change the used RK Method. This also alters the stability function and therefore changes the region of absolute stability. 
It depends on the solved problem and the used $\Delta t$ on how many steps the stability function is altered. For Problems where only a small number of step are affected a bigger change in the stability function would be acceptable. For Problems with require a adaptation of the weights for every step one needs to make sure that the resulting method is stable.

In \ref{proof:combiningb} it is stated that one can construct the stability function of a RKM  $R_b$  with the weights $b = \alpha b_1 + \beta b_2$ by adding the weighted stability functions $R_{\alpha b_a+\beta b_b}(z) = \alpha R_{\alpha b_a}(z) + \beta R_{\beta b_b}(z) $ where all stability functions have the same $A$ and $\alpha + \beta = 1$.

(Todo:It is not straightforward if there are no pole zero cancellations in the stability function. For explicit methods the stability function is a polynomial o degree $\leq s$ (Hundsdorfer). Pole zero cancellations can not happen for these. For implicit functions that are A-stable the poles have to be in the right halve plane. Here is starts to get interesting. Because the A-Stability of one method with a certain $A$ is not a sufficient  condition that there are no Poles for all RKM with this A-Matrix. But it is possible (or easy) to prove that if $a_{ii} > 0 \forall i = 1,\cdots , s$ then there are only poles in the right halve plane where they do not matter for the further considerations.)



(Note:They do not behave like a Vector space because there is no scalar Product, and all the vector have to add up to 1... Is there something simmilar so we don not have to explain everything here?)


If the new $b$ is a chosen as a convex combination of $b$ it is easy to prove that the resulting  the Region of absolute stability is at least the Intersection of the region of absolute stability of the methods that define the convex combination. 



If the $b$ is adapted directly there is no such proof.
A useful property of the resulting stability region is that it is similar to the stability region of the baseline method. 
(Note: is it possible to give some statement like: If the stability regions of the rkm used for multiple steps are similar, then the overall method is stable for the intersection of the stability regions)

Maybe place here some results on the stability region in dependence of the $b$
(Note: I have some proof handy that states that for certain $A$s the boundary of the stability region does only change in regard to a changing b in a limited way. But the proof is a bit convoluted. I have to look if there is a more compact way to prove it)






\section{Implementation aspects of the Algorithm}

(Todo: Maybe a flowchart and a description on how we stitch everything together.) 

The algorithm on adapting the b consists of two main loops. The outer loop loops through all the $\theta$, staring with $\theta = 1$ down to the lowest $\theta$. The inner loop loops through the orders, starting with the highest Order down to the lowest Order. 
Until a acceptable $b$ the algorithm tests combiantions of $\theta$ and $p$. At first the Order Conditions are constructed. On these a LP-Solver is invoiced. If the LP-Problem is infeasible the algorithm immediately tries the next combination. If the LP-Problem is feasible we test if the $b$ is acceptable. At first it is tested weather the new $u^{n+1}$ indeed complies with the constraints. This is necessary because sometimes the used LP-solvers incorrectly identify the problem as feasible. (Note: because of the chosen objective function it can not be unbounded) As second test the deviation from the old solution (Compare Error estimation) is calculated. If the error is bigger than a set maximum error the $b$ is also rejected and the algorithm also switch to the next combination.
As soon as the algorithm finds a suitable $b$ the loops are aborted and the $b$ is used for the update step.
If all the combinations of $\theta$ and $p$ did not lead to a acceptable $b$ the step has to be rejected and a new set of stage values has to bee computed.

(Note: It would also be possible to use another strategy for traversing all the combinations of $(p,\theta)$. Is it worth exploring these?)

(Note: Is here a good place to give a note on where supplementary code can be found?)

(Note: Should we discuss which solver is used. Probably it is not worth using space for some plot etc. on this... Maybe a short note?)



\section{Results of experiments}
\subsection{Explicit methods}
For most of the test problems problems with stability occur before getting negative values. This means that we need methods with large stability region.

\subsubsection{ADP}
A test problem that works good is the advection‐diffusion‐production‐destruction systems. 
For the production‐destruction systems negative values at the intermediate steps occurred. These results of these could be suppressed by the optimization problem  except for some timesteps where these yield to glitches in the solution.

Conclusion: it is important to control for negative Values in the intermediate stages.
Possible solutions: Solve an positifity ensuring optimization Problem at every intermediate step.
Can be formulated as choosing a new $b$ for every intermediate stage which then gets part of $A$ in the next step.

Another idea to explore (Is kind of obvious but could also be stupid): Replace $f(t,u)$ with an $f_{pos}(t,u)$ with 
$f(t,u)=f_{pos}(t,u) \forall u \geq 0 $
Whereas $f_{pos}(t,u)$ is welldefined for $u \leq 0$


We are going to test the solvers for multiple $\Delta t$. For the explicit method we want to show the important times.

$$ \Delta t \; \underset{0}{+}---------\underset{\Delta t_{pos}}{+}\underbrace{--------}_{\gamma}\underset{\Delta t_{feasible}}{+}---\underset{\Delta t_{stable}}{+}--->  $$

\begin{itemize}
\item
$\Delta t_{pos}$ is the largest stepsize that yields to positive results without adapting the $b$

\item
$\Delta t_{feasible}$ is the largest stepsize that can be used with the adaptive $b$

\item
$\Delta t_{stable}$ is the largest stepsize for that the method is stable
\end{itemize}


The timesteps where the adaption of the b is usefull is denoted with $\gamma$ idealy this interval is as large as possible. This means that $\Delta t_{pos} \ll \Delta t_{feasible} \approx \Delta t_{stable}$

With stepsizes $\Delta t > \Delta t_{stable} $ we cann not expect the solution to be reasonable

$\Delta t$ for the ADP Problem 

\begin{tabular}{|c|c|c|c|c|}
\hline 
Method & $\Delta t_{pos}$ &$\Delta t_{stable}$& $\Delta t_{feasible}$  \\ 
\hline
fe & 0.0015 & --- &  0.0051 \\
\hline 
ssp104 fallback =1 & 0.0134 & 0.0309 & 0.0311 \\ 
\hline 
dp5 &0.0031 &0.0031 & 0.0031\\ 
\hline 
ck5 & 0.0044&  0.0044 & 0.0044\\ 
\hline 
merson4 fallback= 1& 0.0038& 0.0055 & 0.0084\\
\hline
\end{tabular} 

We can see that for the ssp104 method is a good choice for this approach when solving this testproblem.  The merson4 method is also suitable. We can not get benefits form dp5 and ck5.


\subsubsection{Quantum Simulations}
Shows following shortcomings:

To ensure positifity we do not only need $\rho_{i,i} \geq 0$ but also the additional constraint $|\rho_{j,k}|^2 \leq \rho_{j,j} \rho_{k,k}$ at least for the elements with $j = k +1$ and $j = k-1$. This conditions can not be formulated as LP-Problem.

\subsection{Implicit methods}
Implicit methods seem like an advantageous choice for a couple of reasons.

\begin{itemize}
\item The computational effort of solving the optimisation Problem is relatively small compared to the overall cost of the method.
\item Implicit methods are stable for large step sizes.
\item Implicit methods ensure positifity for the backward euler step, even for large step sizes.
\item There are no methods for ensuring positifity for higher order methods (Which we also can not get around for the general case)
\end{itemize}

Used for the ADP model the model yields good results, the main limit for the stepsize is the accuracy of the solver for the stageequations.

When tested on the diffusion equation with an spike as initial data the $b$ is only changed for the first step. The change of the $b$ can lead to reasonable changes of the hight of the maximum. 



\section{Useful proofs}

\subsection{Existence of b}
Ensuring a feasible $b$ exists for a certain order condition is in general very difficult.
If we drop the order conditions it is known that there is a positive solution as long as there is a $k_c$ with $k_c \geq 0$.
This is no problem when using a implicit method because a backward euler step always gives a positive solution. 

\subsection{Stability function of linear combinations}\label{proof:combiningb}
Let $R_b(z)$ denote the stability function of a RKM method with the butcher tableau

$$
\begin{array}
{c|c}
c & A\\
\hline
& b^T
\end{array}
$$

We want to prove that $R_{\alpha b_a+\beta b_b}(z)$ = $\alpha R_{ b_a}(z)+\beta R_{b_b}(z)$ when $\alpha + \beta = 1$ and $A$ is the same for all methods.

We start with the definition of the RKM

\begin{align}
u_{n+1} &= u_n + \Delta t K (\alpha b_a+\beta b_b) \label{eq:u_n+1}  \\
u_{n+1}^{sum} &= \alpha (u_n + \Delta t K b_a) + \beta (u_n + \Delta t K b_b) \label{eq:u_n+1_sum} \\
& = (\alpha + \beta) u_n + \Delta t \alpha K b_a + \Delta t \beta K b_b \\
&= u_n + \Delta t K (\alpha b_a+\beta b_b) \\
&=u_{n+1} 
\end{align}

Now we insert the Stability functions for \ref{eq:u_n+1} and \ref{eq:u_n+1_sum} which we already know to be equal. We get 

\begin{align}
u_{n+1} &= u_{n+1}^{sum} \\
R_{\alpha b_a+\beta b_b}(z) u_n &= \alpha R_{\alpha b_a}(z) u_n + \beta R_{\beta b_b}(z) u_n \\
&= (\alpha R_{\alpha b_a}(z) + \beta R_{\beta b_b}(z)) u_n
\end{align}

because this has to be true for all $u_n$ we get

\begin{equation}
R_{\alpha b_a+\beta b_b}(z) = \alpha R_{\alpha b_a}(z) + \beta R_{\beta b_b}(z) 
\end{equation}

\subsection{Stability of convex combination}\label{proof:convex_comb}

With this we can proof that the convex combination of two methods is absolutely stable at the points where both original methods were absolutely stable.

We want to show that $|R_{b_a}(z)|  < 1 ^ |R_{b_b}(z)| < 1\Rightarrow |R_{\chi b_a +(1- \chi) b_b}(z)| < 1$ with $\chi \in [0,1]$.
We write $\alpha = \chi$ and $\beta = 1-\chi$ for convenience.

\begin{align}
|R_{\alpha b_a +\beta b_b}(z)| &= |\alpha R_{b_a}(z) + \beta R_{b_a}(z)| \leq |\alpha R_{b_a}(z)| + |\beta R_{b_a}(z)|\\
 &=| \alpha| \underbrace{|R_{b_a}(z)|}_{<1} + |\beta| \underbrace{|R_{b_a}(z)|}_{<1} < \alpha + \beta = 1
\end{align}


\subsection{Stability of direct adaptation}

We would like to calculate the derivative of the border in respect to a change of $b$. 



The stability function depending on the $b$ is expressed (Note: it is a bit complicated her because we cannot let it depend on the b directly, but only give b after a coordinate transformation, which also makes the expression easier because we can already introduce the order conditions here)
$m$ is the number of dimensions of the Kernel of the Order Condition $m = dim\{Ker Q \}$
The $b_1,\cdots,b_m$  are the Basis vectors of $Ker Q$. By this we can get the vector $w$ by $w = \left[b_1,\cdots,b_m\right]^{-1}(b-b_{orig})$.

The General Stability function of all embedded RKM that satisfy the Order Conditions $Q$ is given by 

\begin{equation}\label{eq:gen_stabilityf}
R(w,z) = (1-(w_1,\cdots,w_m))R_{b_{orig}}(z) + w_1 R_{b_1}(z) + \cdots + w_m R_{b_m}(z)
\end{equation}

The border is defined by the implicit function 
\begin{equation}\label{eq:border}
|R(w,u+iv)|^2 -1 = 0
\end{equation}
This function can be vied either as $\mathbb{R}^m \times  \mathbb{C} \rightarrow \mathbb{R}$ or $\mathbb{R}^m \times  \mathbb{R}^2 \rightarrow \mathbb{R}$.
We are only concerned with the expansion or contraction. Because of this we are only interested in the change perpendicular to the Border of the stability region. 

For a point $z_0= u_0 +i v_0 $ 
with $ |R(w,z_0)|^2 -1 = 0 $ the gradient of
 $|R(w,u,v)|^2$ is calculated. 
If the gradient does not vanish at $z = z_0$ Equation\,\ref{eq:border} Can be transformed in a function $\mathbb{R} \rightarrow \mathbb{R}$ depending on a single variable $a$ by setting $z = z_0 + n a$. The complex number $n$ denotes the normal vector $\vec{n} = \frac{\nabla |R(w,u,v))|^2}{\left| \nabla |R(w,u,v))|^2 \right|}$ of the border of the stability region written in complex notation. This defines the function $a(w)$ with $|R(w,z_0 + n a(w))|^2 -1 = 0$. 
This gives the condition that this approach is only applicable if the gradient does not vanish on the border of the stability function. This is not true in general but for the most common RKM.
The derivative $\frac{\mathrm d}{\mathrm d w} (a(w))$ can be calculated using the implicit function theorem. The defining function is $f: \mathbb{R} \rightarrow \mathbb{R}$ $f(a) = |R(b,z_0 + n a(w))|^2 -1 $ 
If explicit methods are used this function is known to be continuously differentiable because it can be written as a Polynomial of $w_1,\cdots,w_m,u$ and $v$. This is a necessary condition for the use of the of the Implicit function theorem. 
It is also known by definition, that for the point $w=0$ and $z = z_0$ the equation $ |R(w,z_0)|^2 -1 = 0 $ is satisfied.
For simplicity only the formulas for the derivative at the value $b = b_{orig}$ are given. This corresponds to $w_1 = \cdots = w_m = 0$.
The wanted derivative  is given by 

\begin{equation}
 \frac{\partial a}{\partial w_j} (w) =
 - \left[ J_{f,a}(w,a(w))  \right] ^{-1} 
   \left[ \frac{\partial f}{\partial w_j}(w,a(w)) \right]
\end{equation}

as long as the inverse of the Jacobian exists. This is true in most cases as it has been discussed above.

The Jacobian $J_{f,a}(w,a(w))$ evaluated at $w=0$ can be calculated using the directional derivative 
$$ J_{f,a}(b_{orig},a(w)) \Big|_{w=0} = 
 \frac{\partial f}{\partial a} (w,a(w)) \Big|_{w=0} = 
 \nabla |R(w,a(w)|^2 \vec{n} \Big|_{w=0}
= \left| \nabla|R(0,z_0)|^2 \right| = \left| \nabla|R_{b_{orig}}(z_0)|^2 \right|$$ 


The derivative in respect to $w_j$ is 
$ \frac{\partial f}{\partial w_j}(w,a(w)) \Big|_{w=0}$
this simplifies to 
\begin{equation}\label{eq:derivative_to_b}
- 2 \underbrace{R_{b_{orig}}(z_0)R^*_{b_{orig}}(z)}_{=|R_{b_{orig}}(z_0)|^2=1} + R_{b_{orig}}(z_0)R^*_{b_v}(z) + R_{b_v}(z_0)R^*_{b_{orig}}(z_0) 
= -2 + R_{b_{orig}}(z_0)R^*_{b_v}(z_0) + R_{b_v}(z_0)R^*_{b_{orig}}(z_0)
\end{equation}
using the fact that $z_0$ is on the border of the stability region.
The derivative $-2 + R_{b_{orig}}(z_0)R^*_{b_v}(z_0) + R_{b_v}(z_0)R^*_{b_{orig}}(z_0)$ is known to be finite for explicit methods, because $R_{b_v}$ and $R_{b_{orig}}$ are Polynomials and $|z_0| < \infty$
The same process can be done for all points on the border of the stability region. 
As long as $\left[ J_{f,a}(w,a(w))  \right] ^{-1} > 0$ the derivative $\frac{\partial a}{\partial w_j} (w)$ is finite. This means that a small change the $b$ only leads to a small change of the stability region.














\end{document}