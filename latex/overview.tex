\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}

\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary{calc}
\usepackage{color}

\usepackage[backend=biber,url  = false]{biblatex}
\addbibresource{pos_rk_stephan.bib}

\title{Positivity-preserving adaptive Runge-Kutta methods: results}
\author{Stephan Nuesslein}

\begin{document}

\maketitle

\section{Introduction}

A big number of problems that preserve positifity reaction discretiesed PDEs...

With increasing complexity of the right hand side a step requect has a high cost. 
The goal of the project is to develop a positivity preserving method that uses adaptive b-Coefficients for every step.  This means that the computed stage values can be used and don't have to be recomputed. 
The resulting b should comply with the order conditions as far as possible.



(Note: The problem is connected to the theory about embedded methods, in the sense that one have different RKM with the same set of stage values. It may be interesting to have some literature regarding this)

Other Approaches: 


ssp104 methods: The idea is to construct a rkm Method out of explicit euler steps, that lead to a positive result for small enough $\Delta t$. (Todo: Read some literature regarding this and give a short explaination)

Implicit methods: Modified Patanka-Runge-Kutta (MPRK) \cite{kopecz_comparison_2019}

The idea of adapting the $b$ after calculation the stage values is used in \cite{ketcheson_spatially_2013}
In this case it is used to adapt the properties of the time integrator for a method of lines simulation on a PDE. With this approach it is possible to have different properties of the RKM at different parts of the domain. 


(TODO: Outline of paper)

\section{Main Idea}\label{sec:main_idea}

When computing the solution of an ODE $u ' = f(t,u) $ using a RK-Method with $s$ Stages the stage values $k^{(1)},\cdots,k^{(s)}$ are computed according to

\begin{equation}
k^{(j)} =  f(t^n + \Delta t c_j, u^n + \Delta t \sum_{l = 1}^{s} a_{jl} k^{(l)}  \quad j = 1,\cdots,s)
\end{equation}

Based on these values the next solution $u^{n+1}$ is computed by

\begin{equation}
u^{n+1} = u^n + \Delta t \sum_{j  = 1}^s k^{(j)} b_j .
\end{equation}

This equation can be formulated to

\begin{equation}\label{eq:Combination}
u^{n+1} = u^n + \Delta t K b
\end{equation}

where $K$ is a matrix containing the stage values $k_1,\cdots,k_s$.

One reason why steps are requected is that the new solution $u^{n+1}$ does not comply with positifity. 
So it may be adventagious to adapt Equation\,\ref{eq:Combination} in such a way that $u^{n+1}$ is positive. This is done by adapting the weights $b$.
As it can be see in Equation\,\ref{eq:Combination} $u^{n+1}$ is a linear combination of the stage values and the previous solution $u^n$.
When altering the weights the properties of the RKM should be preserved. Especially the Order of the RKM.  
To ensure this the Order Conditions should be still meet. 
Because the coeffeicents $a_{jl}$ are already fixed the Order Conditions reduce to linear equations.
This means that finding the $b$ can be done by solving a linear Programming problem.
 
This approach preserves linear invariants like mass conservation, because it is a regular RKM. 
If there are no negative values in $u^{n+1}$ with the original $b$, then the method does not cause additional effort, because it only has to solve the LP-Problem if the regular RKM does not lead to a positive $u^{n+1}$. (exept for the test)
No additional evaluations of the rhs.

Flowchart to evaluate a step:

\begin{itemize}
\item Calculate the stage values $k_1,\cdots,k_s$
\item Calculate the $u_{n+1} = u_n + \Delta t K b_{d}$ with a default b
\item Test $u_{n+1} \geq 0$, if not:
\item find a new b with $u_n + \Delta t K b \geq 0$
\item Calculate the $u_{n+1} = u_n + \Delta t K b$ with the new b
\end{itemize}

\subsection{Example I}\label{sec:example_reac}

TODO: Add here the reaction equation, show that it behaves better with the new approach. (still keep it simple with fixed stepsize...)

\subsection{Example II}\label{sec:example_lin}

(Note: The primary goal here is to put the idea of changing the b into perspective. We have shown the general idea and how it works, now we want to discuss on what it does in practice. At first we state it is good to preserve the order... Get to the Example ... and show that there is more to it)

By incorporating the Order Conditions for a certain Order the space of $b$ that can be choose is limited to a linear Subspace. 
Now it is important to know if the new solution $u^{n+1}$ still resembles the solution of the ODE $u(t_{n+1})$. 
We can motivate this with the following example:

Take the linear, positifity preserving ODE from \cite{kopecz_unconditionally_2018} with $u = [u_1,u_2]^T$ with the initial conditions $u_0 = [1,0]^T$ and

\begin{equation}
u'(t) = A u(t) \qquad A = \left[\begin{matrix}- a & 1\\a & -1\end{matrix}\right] \quad a =5
\end{equation}

and the first order RKM with two stages

\begin{align}
\begin{array}{c|cc}
0 &  & \\
\frac{1}{2} & \frac{1}{2} & \\
\hline
 & \frac{1}{2} & \frac{1}{2}\\
\end{array}
\end{align}

If simulated with $\Delta t = 1$ the stage values are 

\begin{equation}
k^1 = \left(\begin{matrix}-5\\5\end{matrix}\right) \qquad k^2 = \left(\begin{matrix}10\\-10\end{matrix}\right)
\end{equation}

All $b$ that comply with the order Condition for the first order can be expressed as

\begin{equation}
b= \left(\begin{matrix}\frac{1}{2}\\ \frac{1}{2}\end{matrix}\right) + \alpha \left(\begin{matrix}1\\ -1\end{matrix}\right)
\end{equation}

Therefor the general solution is 

\begin{equation}
u^{1} = u^0 + \Delta t  \left[k^1,k^2\right] b = \left(\begin{matrix}\frac{5}{2}\\- \frac{5}{2}\end{matrix}\right) \alpha  \left(\begin{matrix}-15\\15\end{matrix}\right)
\end{equation}

By a suitable choice of $\alpha \in [\frac{1}{6},\frac{7}{30}]$ any $u$ that complies with mass conservation and positifity can be reached. 

This gives raise to the question weather the new solution is reasonable.
This also poses the problem on developing a system that can decide if the new solution is has to be rejected. 




\section{Details}\label{sec:Deta	ils}



\subsection{Order Conditions}\label{sec:OrderCond}

The Order Conditions for a RKM are a set of Equations depending on $a_{jl}$, $c_1,\cdots,c_s$ and $b_1,\cdots,b_s$. In these Equations $b_1,\cdots,b_s$ only appear linearly \cite{hairer_runge-kutta_1993}.
If $a_{jl}$ and $c_1,\cdots,c_s$ are already known, the Order Conditions for the Order $p$ are an linear equations system and can be written as $Q b = r$. 

The vector $b \in \mathbb{R}^s$ contains the weights and $Q$ is an $n \times s$ matrix, where $g$ is the number of Order Conditions. The vector $r$ contains the right hand side of the Order Conditions.

If the $A$ of a  preexisting RK-method is used, there is at least one solution for the linear equation system.
In order to get an optimization problem the equation system has to be underdetermined.
This implies that $\mathrm{rank}(Q) < s$. 
Because the Quadrature Conditions are linear independent, there are at least $p$ independent vectors in $Q$. This leads to the condition $p < s$.
This implies that the number of stages has to be higher as the wanted order.


\subsection{Ways to formulate the Optimization Problem}

There are two possible ways to write down the adaptation of the $b$. The first way is to directly adapt the original weights $b_{orig}$ by adding a correction $\Delta b$ that ensures positivity.
This is the easiest way to adapt the $b$. An advantageous property is that the step size can be reduced after calculation the stage values by using the dense output order conditions.  
This approach suits best for explicit methods.
The direct adaption approach is explained in more detail in section\,\ref{sec:direct}.

The second approach is to choose $b$ as a convex combination of a set of $b$s. This approach is more useful if some embedded methods with certain properties are know. 
This approach also shows more  predictable behavior because the resulting $u^{n+1}_b$ is also a convex combination of the solutions $u^{n+1}_{b_a},u^{n+1}_{b_b},\cdots$ 
This approach works best with implicit methods.
The direct adaption approach is explained in more detail in section\,\ref{sec:convex}

Both approaches are shown in figure\,\ref{fig:b_space}.


\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \input{Image_b_direct}
        \caption{Direct Adaptation}
        \label{fig:b_direct}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \input{Image_b_convex}
        \caption{Convex Combiantion}
        \label{fig:b_convex}
    \end{subfigure}
    \caption{Graphical representation of the two different approaches to adapt the weights}\label{fig:b_space}
\end{figure}

\subsection{Direct Adaptation}\label{sec:direct}

When directly adapting the $b$ a new $b$ that complies with the Order Conditions is chosen.   
The weights $b = b_{orig} + \Delta b$ consist of the weights of the original method $b_{orig}$ and an adaption $\Delta b$. This $\Delta b \in \mathrm{ker}(Q)$. 
In Figure\,\ref{fig:b_direct} this is drawn. The red line represents the subspace of $b$ that satisfy the Order Conditions. Both $b_{orig}$ and $b$ are in this subspace. 
 
To run it as a LP-Problem a set of constraints is constructed.  
Also a objective function is needed to determine the optimal $b$.

\subsubsection{Constraints}
The Direct Adaptation approach leads to two set of constraints on the $b$.

The first set of constraints is the positifity and can be written as 
$$u_{n+1}=u_n+\Delta K \vec{b} \geq 0$$

The second set of constraints are the Order Conditions
$$Qb=r$$



\subsubsection{Objective Function}
Different types of objective functions have been tried. 

\begin{description}

\item[L1 norm] The optimisation Problem opimises for $min(|b-rkm.b|_1)$
            
\item[Quadrature]   The optimisation Problem opimises for $min(|b^Tq-r|)$
                            where q is the quadrature condition of the next higher order 
                            and r is the expected right hand side
            
\item[Hom. Order]    The optimisation Problem opimises for $min(|bTO|)$ where O are the homogenus Order Conditions of the next higher orders
                            
 
\end{description}

A reasonable property of the objective function would be that for the LP-Problem only constrained by the order condition the optimal solution is $b = b_{orig}$. 
This can be achieved by $argmin(f_{optim}(b)) = b_{orig}$. 
In practice this also means that there is no need to solve solve the optimization Problem if no constraints are violated because the solution of this problem is already known. This is adventagious for performance reasons.
The different approaches have been tested on a linear test problem from \cite{kopecz_unconditionally_2018}. The optimization problem was used at every step.
The magnitude of $b$ can get large if the Order Conditions are used as objective function.
Large values of b can lead to numerical problems. Because $\sum_{i  = 1}^s b_i = 1$, a increase of $||b||$ leads to a combination of negative and positive values. Because the computation only is done with a finite precision (and usually in floating point) large $||b||$ can lead to absorption effects.    
By changing the $b$ the stability function is altered. This can lead to oscillations if the poles of the RHS are no longer in the stability region of the resulting method.
For these reasons $||b-b_{orig}||$ seems like a good choice. The 1-Norm can be implement the with Linear Programming using slack variables. We choose 

\begin{equation}
f_{obj} = ||b_{optim}-b_{orig}||_1
\end{equation}
 as objective function.




\subsubsection{Adaption of Timestep using the dense output formual}

If the original step $\Delta t$ was to large and there is no suitable $b$, we would like to calculate a $u^{n+1}$ using the stage values instead of rejecting the step. For this the time step is reduced after calculation the stage values. This can be done using the Order Conditions for dense Output. These can be found in \cite{hairer_runge-kutta_1993}.
We introduce $\theta \in (0,1]$. The new step taken has the length $\theta \Delta t$ whereas $\Delta t$ is the time step used when calculating the Stagevalues.
To calculate a reduced step the Order Conditions have to be adapted and a new $b_{orig}$ for the objective function (and more important the Error detection afterwards) has to be generated. 
(TODO: the $b_{orig}$ is still a open question)

When adapting the Order Condition to a new $\theta$ the Order Condition Matrix $Q$ stays unchanged whereas the right hand side depends on $\theta$.

The dependency of $r(\theta)$ is nonlinear. This means that the maximum $\theta$ with a suitable $b$ can not be calculated by solving a LP-Problem. This means that different $\theta$ have to be tested independently. 
(Note: we could include some algorithm to search for it)


\subsection{Convex combination of existing methods}\label{sec:convex}
For some test problems (e.g. the Heat Equation solved with an implicit method of higher order), large distortions occur, even though a norm of the distortion of the b is used as a objective function. 
For implicit methods it is known that the backward euler steps lead to a positive solution for any $\Delta t$ \cite{hundsdorfer_numerical_2003}. The backward Euler is still only first Order but shows more exact results than a method of higher Order that is distorted by the adaption of the $b$, at least at some steps. 
A possible method to fix this is to generate the new b based on a convex combination of embedded methods of RKM. 

\subsubsection{Constraints}
At first a set of embedded methods of the RKM $b_1,\cdots,b_d$ are needed. 
If all the used $b$ compile with the order conditions the new method is also of the same Order.
This is straightforward using

$$ Q b = Q (\chi b_{\alpha} + (1-\chi) b_{\beta}) = \chi Q  b_{\alpha} + (1-\chi) Q b_{\beta}) = \chi r + (1-\chi) r = r$$

$b_{\alpha}$ and $b_{\beta}$ are the methods that are combined to $b$ using the parameter $\chi$. The Matrix $Q$ and the vector $r$ are the Order Conditions as defined in Section\,\ref{sec:OrderCond}.

The new $b$ is defined as 
\begin{equation}\label{eq:b_convex_def}
\vec{b} = \sum_i^d a_i \vec{b_i} = Ba
\end{equation}


where $B=\left[b_1,\cdots,b_d \right]$ is a matrix containing the embedded methods.  
To ensure the that Equation\,\ref{eq:b_convex_def} yields a convex combination following constraints are enforced for the  the parameters $a,\cdots,a_d$.

\begin{equation}
 0 \leq a_1 \leq 1  \forall_{i \in \{1, \cdots d \}}
\end{equation}
\begin{equation}
 \sum_{i=1}^d a_i = 1
\end{equation}


The positifity constraint changes to 

$$u_{n+1}=u_n+\Delta t K B a \geq 0$$

where $a = [a_1,\cdots,a_d]^T$


\subsubsection{Objective Function}

As an Objective function the function

\begin{equation}
f_{obj} = min \left(\sum_i^d w_i a_i \right)
\end{equation}

is used.  The $w_1,\cdots,w_d$ are weighting factors that determine which is the preferred $b_i$ to use.

Because the optimal solution of the unconstrained problem has to be the original $b$ the weight $w_0$ corresponding to $b_{orig}$ should be the smallest $w$. This weight is simply set to $w_{b_{orig}} = 0$. For the other weights $w_i = \frac{1}{\mathrm{Order} \{b_i\}}$ is used.

\subsubsection{Construction of Embedded Methods}
For methods with $s \geq p$ it is useful to have some degrees of freedom for the highest order. For this at least one $b$ that complies with the order Condition of the highest order and $b \neq b_{orig}$ has been introduced.
These additional $b$ can be constructed by calculating a Span $S$ of the Kernel $\mathrm{ker} (Q)$ of the Order Condition Matrix $Q$. For every vector $s \in S$ one set of weights with $b = b_{orig} + a s$ and one with $b = b_{orig} - a s$ is added. The $a$ is a parameter that determines how big a change is allowed. 

As a first order method a $b$ is added that corresponds to a series of backward euler steps. These are know to be yield to a positive result.

An important property of the embedded methods is that they should show the desired stability characteristics.

A Reduction of the step size suing the order Conditions for dense output would also be possible. For this a set of embedded methods $b_1(\Theta),\cdots,b_d(\Theta)$ has to be constructed. This was not done in this research.

(Note: Doing dense Output here is a bit complicated, but it would not help ensure positifity only (maybe) increase exactness.  is it worth exploring this or is it better to just leave this open for further research it may be also interesting regardless the study of positifity)
Everything has downsides...
 


\subsection{Choice of Baseline Method}
An important property for the used baseline method is the Existence of embedded methods and the degrees of freedom for the b.
As noted in Section\,\ref{sec:OrderCond} the number of Stages has to be higher than the Order. 
Another important property is the number of degrees of freedom for the choice of the new weights. 
These can be calculated using $s-\mathrm{rank}(Q)$%$\mathrm{dim}(\mathrm{ker}(Q))$.
The number of degrees of freedom for different methods are shown in table\,\ref{table:DOF_exp} for explicit methods and in table\,\ref{table:DOF_imp} for implic methods.

\begin{table}[h!]
\centering    %Generated below============ 
\begin{tabular}{|l |c c c c c c |} 
 \hline 
Order &1&2&3&4&5&6 \\ 
 \hline Classical RK4&3&2&0&0& - & -  \\ 
 SSPRK(10,4)&9&8&6&4& - & -  \\ 
 Cash-Karp RK5(4)6&5&4&2&1&0& -  \\ 
 Dormand-Prince RK5(4)7&6&5&3&1&0& -  \\ 
 \hline 
 \end{tabular}
 \caption{Degrees of Freedom for Choice of $b$} %Generated above============ 
 \label{table:DOF_exp}
 \end{table}
 
 \begin{table}[h!]
\centering   %Generated below============ 
 \begin{tabular}{|l |c c c c c c |} 
 \hline 
Order &1&2&3&4&5&6 \\ 
 \hline Implicit Euler&0& - & - & - & - & -  \\ 
 Im-Euler 2&2&1& - & - & - & -  \\ 
 Im-Euler 3&5&4&2& - & - & -  \\ 
 Im-Euler 4&9&8&6&3& - & -  \\ 
 \hline 
 \end{tabular}
 \caption{Degrees of Freedom for Choice of $b$} %Generated above============ 
 \label{table:DOF_imp}
 \end{table}


For all methods with the number of stages equal to the order of the method, there are no degrees of freedom without reducing the order. 
If the Classical RK4 method is used the Order has to reduced more because the RK4 method does not have embedded methods of order 3.
Contrary to this methods with $s > p$ have degrees of freedom even without reducing the order. 

Another important property is the stability region in comparison with the maximum $\Delta t$ that ensures positifity. For this approach to be useful the RK-method has to yield negative results for $\Delta t$ smaller than the biggest stable $\Delta t$.

(Note: up to this point i do not understand why this is happening. We only see it occur depending on the Proble-RKM combination)

A third property is the existence of a positive solution. This corresponds to the question if there is a embedded first order method that ensures positivity. This is particularly interesting for Implicit methods, because the $\Delta t$ is not limited by the stability. 
If we have a embedded first Order Method we can ensure that there is always a positive solution, which might be of first Order. (Todo: Source)

\subsection{Error detection and Approximation}
When changing the weights the solution $u^{n+1}$ is changed. 
By incorporating the Order Conditions for a certain Order the space of $b$ that can be choose is limited to a linear Subspace. 
Now it is important to know if the new solution $u^{n+1}$ still resembles the solution of the ODE $u(t_{n+1})$. 
This can be seen in example in section\,\ref{sec:example_lin}.
By a suitable choice of $\alpha \in [\frac{1}{6},\frac{7}{30}]$ any $u$ that complies with mass conservation and positifity can be reached. 

This gives raise to the question weather the new solution is reasonable.
This also poses the problem on developing a system that can decide if the new solution is has to be rejected. 


 
\subsubsection{Error Detection}
For this approach is difficult to give some mathematically rigorous statement regarding the convergence of the method, because it only applies if the error of the original method causes the solution to get negative. This can only happen if the Truncation error is large enough. This requires $\Delta t \gg 0$ where lower coefficients of the Taylor Series are no longer sufficient to approximate the behavior. 
One could say that the main idea of the adaption of $b$ is to alter the error in a certain way, so that the numerical solution gets 'better' in the sense that it leads to positive solutions. 
The local error of a RKM $e(\Delta t) =u(t_0 + \Delta t) - u^1$ can be expressed using the Taylor series of the RKM and the Taylor series of the exact solution. % Hairer I P134

\begin{align}\label{eq:Taylor_sol_ref}
u(t_0 + \Delta t) &= u(t_0) + u'(t_0) \Delta t + \frac{u''(t_0)}{2} \Delta t^2 + \cdots + \frac{u^{(p)}(t_0)}{p!} \Delta t^p + \frac{u^{(p+1)}(t_0)}{(p+1)!} \Delta t^{p+1} + \cdots \\
u^{n+1} &= u(t_0)  + v_1 \Delta t + \frac{v_2}{2} \Delta t^2 + \cdots + \frac{v_p}{p!} \Delta t^p + \frac{v_{p+1}}{(p+1)!} \Delta t^{p+1} + \cdots \\
\end{align}

The derivatives of $u(t)$ can be solely expressed with the partial derivatives of the RHS $f(t,u)$, whereas the coefficients $v_1,v_2,\cdots$ also depend on the RKM. 
In this case the RKM is fixed apart from the weights $b$. 
Because of this $v_1,v_2,\cdots$ are functions of $b$.
Because the $b$ are chosen to ensure the Order Conditions the coefficients $v_1,\cdots,v_p$ are fixed and equal the according derivatives. 
The only remaining degrees of freedom are the coefficients $v_{p+1},v_{p+2},\cdots$.
These can be adapted by changing the $b$.

The main way is to ensure that the RKM with adapted b i to ensure that the $b$ approach $b_{orig}$ for $\Delta t \to 0$. For this $b$ it is already know that the numeric solution converges to the exact solution.  
This is made sure by property of the Objective function that 

\begin{equation}
\mathrm{argmin}(f_{optim}(b)) = b_{orig}
\end{equation}

This approximation is not very useful for real applications. 
To approximate the error of a new step we propose following approxiamtion of the local error:

\begin{align}
err = |u(t^n)-u^n| &= |u(t^n) - (u^n_{b_{orig}+\Delta t K(b-b_{orig})})| \\
 &\leq \underbrace{|u(t^n)-u^n_{b_{orig}}|}_{\approx err_T}+\underbrace{|\Delta t K(b-b_{orig})|}_{= err_{adapt}}
\end{align}

After adapting the $b$ the Approximation Error is checked. If $|\Delta t K(b-b_{orig})|$ is larger than the tolerance the $b$ is requected. 

\subsubsection{Steppsize Control}
An important part of an RKM method is the ability to approximate the error of the solution to use it to control the step size. 
The truncation error $|u(t^n)-u^n_{b_{orig}}|$ is usually approximated with an standard error estimator $err_T = | u^{n}_{b_{orig}} - u^{n}_{\hat{b}} |$.

Both errors are added to get an approximation of the total error $err = err_T +w_a err_{adapt}$. The parameter $w_a \leq 1$ is used to account for the fact that the real error is smaller than $err = err_T +err_{adapt}$. The factor also improves the stability of the step size control because $err_{adapt}$ is not as smooth as $err_T$, especially if negative values only occur for a small number of steps.
If the LP-Problem was infeasible and no $b$ was found the $err_{approx}$ is set to a custom value. This value should be chosen sufficiently large to ensure that the next step take is smaller, but still not to large to keep the stepsize control stable.

This type of error estimation is easy to implement because it can be easily incorporated in an existing step size control and takes advantage of the standard error approximation.

%To make sure that the new adapted solution is still reasonable we measure the deviation form the Original method. In the worst case the errors add up. (todo: here some math formula... (We know that can not be the case because we already know that we will reduce the error for the quantity we will make positive, still we can use it as a upper bound.))


\subsection{Stability Region}

By adapting the $b$ the used RK Method is changed. This also alters the stability function and therefore changes the region of absolute stability. 
It depends on the solved problem, the RKM and the used $\Delta t$ on how many steps the stability function is altered. For Problems where only a small number of step are affected a bigger change in the stability function would be acceptable. For Problems with require a adaptation of the weights for every step one needs to make sure that the resulting method is stable.


The stability function of a RKM  $R_b$  with the weights $b = \alpha b_1 + \beta b_2$ cn be calculated by adding the weighted stability functions $R_{\alpha b_a+\beta b_b}(z) = \alpha R_{\alpha b_a}(z) + \beta R_{\beta b_b}(z) $ where all stability functions have the same $A$ and $\alpha + \beta = 1$.

Let $R_b(z)$ denote the stability function of a RKM method with the butcher tableau

$$
\begin{array}
{c|c}
c & A\\
\hline
& b^T
\end{array}
$$

We want to prove that $R_{\alpha b_a+\beta b_b}(z)$ = $\alpha R_{ b_a}(z)+\beta R_{b_b}(z)$ when $\alpha + \beta = 1$ and $A$ is the same for all methods.

We start with the definition of the RKM

\begin{align}
u_{n+1} &= u_n + \Delta t K (\alpha b_a+\beta b_b) \label{eq:u_n+1}  \\
u_{n+1}^{sum} &= \alpha (u_n + \Delta t K b_a) + \beta (u_n + \Delta t K b_b) \label{eq:u_n+1_sum} \\
& = (\alpha + \beta) u_n + \Delta t \alpha K b_a + \Delta t \beta K b_b \\
&= u_n + \Delta t K (\alpha b_a+\beta b_b) \\
&=u_{n+1} 
\end{align}

Now we insert the Stability functions for \ref{eq:u_n+1} and \ref{eq:u_n+1_sum} which we already know to be equal. We get 

\begin{align}
u_{n+1} &= u_{n+1}^{sum} \\
R_{\alpha b_a+\beta b_b}(z) u_n &= \alpha R_{\alpha b_a}(z) u_n + \beta R_{\beta b_b}(z) u_n \\
&= (\alpha R_{\alpha b_a}(z) + \beta R_{\beta b_b}(z)) u_n
\end{align}

because this has to be true for all $u_n$ we get

\begin{equation}
R_{\alpha b_a+\beta b_b}(z) = \alpha R_{\alpha b_a}(z) + \beta R_{\beta b_b}(z) 
\end{equation}


%(Todo:It is not straightforward if there are no pole zero cancellations in the stability function. For explicit methods the stability function is a polynomial o degree $\leq s$ (Hundsdorfer). Pole zero cancellations can not happen for these. For implicit functions that are A-stable the poles have to be in the right halve plane. Here is starts to get interesting. Because the A-Stability of one method with a certain $A$ is not a sufficient  condition that there are no Poles for all RKM with this A-Matrix. But it is possible (or easy) to prove that if $a_{ii} > 0 \forall i = 1,\cdots , s$ then there are only poles in the right halve plane where they do not matter for the further considerations.)



\subsubsection{Stability of convex combination}
If the new $b$ is chosen as a convex combination of $b$ it is easy to prove that the resulting  the Region of absolute stability is at least the Intersection of the region of absolute stability of the methods that define the convex combination. (Compare Section\,\ref{proof:convex_comb}). This also means that if all the used embedded methods used to construct the new $b$ are A-Stable, the resulting method is also A-Stable.

With this we can proof that the convex combination of two methods is absolutely stable at the points where both original methods were absolutely stable.

We want to show that $(|R_{b_a}(z)|  < 1) (|R_{b_b}(z)| < 1) \Rightarrow |R_{\chi b_a +(1- \chi) b_b}(z)| < 1$ with $\chi \in [0,1]$.
We write $\alpha = \chi$ and $\beta = 1-\chi$ for convenience.

\begin{align}
|R_{\alpha b_a +\beta b_b}(z)| &= |\alpha R_{b_a}(z) + \beta R_{b_a}(z)| \leq |\alpha R_{b_a}(z)| + |\beta R_{b_a}(z)|\\
 &=| \alpha| \underbrace{|R_{b_a}(z)|}_{<1} + |\beta| \underbrace{|R_{b_a}(z)|}_{<1} < \alpha + \beta = 1
\end{align}



\subsubsection{Stability of  Direct Adaptation}
If the $b$ is adapted directly there is no such proof.
A useful property of the resulting stability region is that it is similar to the stability region of the baseline method. 
(Note: is it possible to give some statement like: If the stability regions of the rkm used for multiple steps are similar, then the overall method is stable for the intersection of the stability regions)

For most methods a small change of $b$ does not alter the stability function dramatically.

We would like to calculate the derivative of the border in respect to a change of $b$. 

The stability function depending on the $b$ is expressed (Note: it is a bit complicated her because we cannot let it depend on the b directly, but only give b after a coordinate transformation, which also makes the expression easier because we can already introduce the order conditions here)
$m$ is the number of dimensions of the Kernel of the Order Condition $m = \mathrm{dim}\{\mathrm{Ker} (Q) \}$
The $b_1,\cdots,b_m$  are the Basis vectors of $\mathrm{Ker} (Q)$. By this we can get the vector $w$ by $w = \left[b_1,\cdots,b_m\right]^{-1}(b-b_{orig})$.

The General Stability function of all embedded RKM that satisfy the Order Conditions $Q$ is given by 

\begin{equation}\label{eq:gen_stabilityf}
R(w,z) = (1-(w_1,\cdots,w_m))R_{b_{orig}}(z) + w_1 R_{b_1}(z) + \cdots + w_m R_{b_m}(z)
\end{equation}

The border is defined by the implicit function 
\begin{equation}\label{eq:border}
|R(w,u+iv)|^2 -1 = 0
\end{equation}
This function can be viewed either as $\mathbb{R}^m \times  \mathbb{C} \rightarrow \mathbb{R}$ or $\mathbb{R}^m \times  \mathbb{R}^2 \rightarrow \mathbb{R}$.
We are only concerned with the expansion or contraction. Because of this we are only interested in the change perpendicular to the Border of the stability region. 

For a point $z_0= u_0 +i v_0 $ 
with $ |R(w,z_0)|^2 -1 = 0 $ the gradient of
 $|R(w,u,v)|^2$ is calculated. 
If the gradient does not vanish at $z = z_0$ Equation\,\ref{eq:border} Can be transformed in a function $\mathbb{R}^m \times \mathbb{R} \rightarrow \mathbb{R}$ depending on $w$ and a single variable $a$ by setting $z = z_0 + n a$. The complex number $n$ denotes the normal vector $\vec{n} = \frac{\nabla |R(w,u,v))|^2}{\left| \nabla |R(w,u,v))|^2 \right|}$ of the border of the stability region written in complex notation. This defines the function $a(w)$ with $|R(w,z_0 + n a(w))|^2 -1 = 0$. 
This implies that this approach is only applicable if the gradient does not vanish on the border of the stability function. This is not true in general but for the most common RKM.
The derivative $\frac{\mathrm d}{\mathrm d w} (a(w))$ can be calculated using the implicit function theorem. The defining function is 
\begin{equation}\label{eq:f(w,a)}
f: \mathbb{R}^m \times \mathbb{R} \rightarrow \mathbb{R} f(a) = |R(w,z_0 + n a)|^2 -1 
\end{equation}

If explicit methods are used this function is known to be continuously differentiable because it can be written as a Polynomial of $w_1,\cdots,w_m,u$ and $v$. This is a necessary condition for the use of the of the Implicit function theorem. 
It is also known by definition, that for the point $w=0$ and $z = z_0$ the equation $ |R(w,z_0)|^2 -1 = 0 $ is satisfied.
For simplicity only the formulas for the derivative at the value $b = b_{orig}$ are given. This corresponds to $w_1 = \cdots = w_m = 0$.
The wanted derivative  is given by 

\begin{equation}
 \frac{\partial a}{\partial w_j} (w) =
 - \left[ J_{f,a}(w,a(w))  \right] ^{-1} 
   \left[ \frac{\partial f}{\partial w_j}(w,a(w)) \right]
\end{equation}

as long as the inverse of the Jacobian exists. This is true in most cases as it has been discussed above.

The Jacobian of equation\,\ref{eq:f(w,a)} $J_{f,a}(w,a(w))$ evaluated at $w=0$ can be calculated using the directional derivative
\begin{align*}
 J_{f,a}(b_{orig},a(w)) \Big|_{w=0} =& 
 \frac{\partial f}{\partial a} (w,a(w)) \Big|_{w=0} = 
 \nabla |R(w,a(w)|^2 \vec{n} \Big|_{w=0} \\
=& \left| \nabla|R(0,z_0)|^2 \right| = \left| \nabla|R_{b_{orig}}(z_0)|^2 \right|
\end{align*} 

The derivative in respect to $w_j$ is 
$ \frac{\partial f}{\partial w_j}(w,a(w)) \Big|_{w=0}$
this simplifies to 
\begin{align*}\label{eq:derivative_to_b}
 \frac{\partial f}{\partial w_j}(w,a(w)) \Big|_{w=0} =&
- 2 \underbrace{R_{b_{orig}}(z_0)R^*_{b_{orig}}(z_0)}_{=|R_{b_{orig}}(z_0)|^2=1} + R_{b_{orig}}(z_0)R^*_{b_v}(z) + R_{b_v}(z_0)R^*_{b_{orig}}(z_0) \\
=& -2 + R_{b_{orig}}(z_0)R^*_{b_v}(z_0) + R_{b_v}(z_0)R^*_{b_{orig}}(z_0)
\end{align*}
using the fact that $z_0$ is on the border of the stability region.
The derivative $-2 + R_{b_{orig}}(z_0)R^*_{b_v}(z_0) + R_{b_v}(z_0)R^*_{b_{orig}}(z_0)$ is known to be finite for explicit methods, because $R_{b_v}$ and $R_{b_{orig}}$ are Polynomials and $|z_0| < \infty$
The same process can be done for all points on the border of the stability region. 
As long as $\left[ J_{f,a}(w,a(w))  \right] > 0$ the derivative $\frac{\partial a}{\partial w_j} (w)$ is finite. This means that a small change the $b$ only leads to a small change of the stability region.



\section{Implementation aspects of the Algorithm}

TODO: Discuss in this section aspects that are needed for implementation (and improve the usability) but do not concern the mathematical idea of the approach.

\subsection{Positifity}


For the further discussion we are concerned with a System of $m$ coupled ODEs. 
In this setup  $u \in \mathbb{R}^m$.
Systems of ODEs with a high number of dimensions can appear when solving a PDE with the method of lines.

To enshure that the solution is positive 

\begin{align}
 u_i^{n+1} &\geq 0   \;   \forall_{i \in \{1, \cdots,m \}}  \\
 u_i^n + h \sum_{j=0}^{s-1} b_j k_i^j  &\geq 0   \;   \forall_{i \in \{1,\cdots,m \}}  
\end{align}

has to be fulfilled.
This infers $m$ positivity constraints to the optimisation problem. These can be written as

\begin{equation}
u_i + \Delta t K  b \geq 0     
\end{equation}

where $K = \big[k^1 , \cdots k^{s-1}\big]$.

This causes unnecessary many inequality constraints on the LP-Problem. To simplify the problem one want to reduce the number of positifity constraints by ignoring it for ODEs where there is no issue with positifity.

The new positifity constraints can be formulated as
\begin{equation}
u_i^n + \Delta b \sum_{j=0}^{s-1} b_j k_i^j  \geq 0   \;   \forall_{i \in h \subseteq \{1,\cdot,m \}} 
\end{equation}

For this a set $h \subseteq \{1,\cdots,m \}$ that include all indecies that are needed for determining the $b$ has to be chosen.

A reasonable approach is to set $h_0 = \{ i \in \{1,\cdots,m \} |  u_i^{n+1}  < 0 \}$. 
After the new $b$ and $u^{n+1}$ is computed using $h_0$, the algorithm has to check if the positifity of the other values $u_i | i \notin h_0 \subseteq \{1,\cdots,m \}$ is still meet. 
If the conditions is not meet a new set $h_{a+1} = \{ i \in \{1,\cdots,m \}|  u_i^{n+1}  < 0 \} \cup h_{a}$ using the new $u^{n+1}$ is generated and the LP-Problem is solved again. This process id repeated until a solution is found that leads to a $u^{n+1} \geq 0$. The choice of $h_{a+1}$ based on the $h_{a}$ ensures that the algorithm cannot get stuck in a loop. In the worst case $h_a$ is growing very slowly until $h_a = \{1,\cdots,m \}$. 

This effect did not occur so far. 
(Note: A approach on this would be to make a educated guess which indecies could get a problem with positifity. A possible estimate would be $\frac{u_i^{n+1}}{max(K_{(i,0)}, \cdots ,K_{(i,0)})} $ )

When enforcing a maximum value the number of constraints can be reduced using the same technique. When both enforcing maximum and minimum values two separate sets of active constraints $k_{min}$ and $k_{max}$ are used. The set $k_{max}$ denotes the active maximum constraints and the set $k_{min}$ denotes the active minimum constraints. 
Here it is important to update these sets simultaneously.  

\subsection{•}
(Todo: Maybe a flowchart and a description on how we stitch everything together.) 

The algorithm on adapting the b consists of two main loops. The outer loop loops through all the $\theta$, staring with $\theta = 1$ down to the lowest $\theta$. The inner loop loops through the orders, starting with the highest Order down to the lowest Order. 
Until a acceptable $b$ the algorithm tests combiantions of $\theta$ and $p$. At first the Order Conditions are constructed. On these a LP-Solver is invoiced. If the LP-Problem is infeasible the algorithm immediately tries the next combination. If the LP-Problem is feasible we test if the $b$ is acceptable. At first it is tested weather the new $u^{n+1}$ indeed complies with the constraints. This is necessary because sometimes the used LP-solvers incorrectly identify the problem as feasible. (Note: because of the chosen objective function it can not be unbounded) As second test the deviation from the old solution (Compare Error estimation) is calculated. If the error is bigger than a set maximum error the $b$ is also rejected and the algorithm also switch to the next combination.
As soon as the algorithm finds a suitable $b$ the loops are aborted and the $b$ is used for the update step.
If all the combinations of $\theta$ and $p$ did not lead to a acceptable $b$ the step has to be rejected and a new set of stage values has to bee computed.

(Note: It would also be possible to use another strategy for traversing all the combinations of $(p,\theta)$. Is it worth exploring these? Eg, a visect algorithm for $\Theta$ or linear approximations)



\section{Results of experiments}\label{sec:Numeric_Results}

(Note: Is here a good place to give a note on where supplementary code can be found?)

(Note: Should we discuss which solver is used. Probably it is not worth using space for some plot etc. on this... Maybe a short note?)

\subsection{Applicable Problems}\label{sec:app_problem}
The approach can be used with ODE systems $u' = f(t,u)$ that ensure  $u(t) \geq 0 \forall_t \forall_{  u_0 \geq 0}$ 

This can be tested with the property 
\begin{equation}
u_i=0 \Rightarrow f_i(t,u_1,\cdots,u_i,\cdots,u_n) \geq 0  \forall_{u_c \geq 0} \forall_{t}
\end{equation}

For problems where the exact solution is positive for certain $u_0$ but positifity is not preserved for all $u_0 \geq 0$ tests did not show promising results. Additional it is not certain if the computed solutions would be reasonable.


\subsection{Explicit methods}
For most of the test problems problems with stability occur before getting negative values. This means that we need methods with large stability region.



\subsection{Implicit methods}
Implicit methods seem like an advantageous choice for a couple of reasons.

When tested on the diffusion equation with an spike as initial data the $b$ is only changed for the first step. The change of the $b$ can lead to reasonable changes of the hight of the maximum. 

\subsection{Stepsize control}

\subsection{Dense Output}






\printbibliography



\end{document}